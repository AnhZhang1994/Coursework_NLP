{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947e4293-2ea9-49e8-8465-34dba106d3e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6617,
     "status": "ok",
     "timestamp": 1654607949840,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "947e4293-2ea9-49e8-8465-34dba106d3e5",
    "outputId": "5cd6d3f5-e5f5-4db4-a2d9-2e31fca4c339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /home/seclab_taewan/.local/lib/python3.9/site-packages (from seqeval) (1.22.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/seclab_taewan/.local/lib/python3.9/site-packages (from seqeval) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/seclab_taewan/.local/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/seclab_taewan/.local/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/seclab_taewan/.local/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=f80c906ebdaa4d470f8a8801851ad2bff460848c121bfbd1cfee63edf66ff0eb\n",
      "  Stored in directory: /home/seclab_taewan/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/etc/anaconda3/envs/test/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ! pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f2c381-3a35-404b-8c96-6982a00b1a29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16830,
     "status": "ok",
     "timestamp": 1654607966661,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "42f2c381-3a35-404b-8c96-6982a00b1a29",
    "outputId": "fc64f9f3-f786-4f61-820f-b3a8a86f5711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from pytorch-transformers) (2022.4.24)\n",
      "Requirement already satisfied: sacremoses in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from pytorch-transformers) (0.0.49)\n",
      "Requirement already satisfied: tqdm in /home/seclab_taewan/.local/lib/python3.9/site-packages (from pytorch-transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /home/seclab_taewan/.local/lib/python3.9/site-packages (from pytorch-transformers) (2.27.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from pytorch-transformers) (1.11.0)\n",
      "Requirement already satisfied: numpy in /home/seclab_taewan/.local/lib/python3.9/site-packages (from pytorch-transformers) (1.22.2)\n",
      "Requirement already satisfied: sentencepiece in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from pytorch-transformers) (0.1.96)\n",
      "Requirement already satisfied: boto3 in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from pytorch-transformers) (1.22.1)\n",
      "Requirement already satisfied: typing-extensions in /home/seclab_taewan/.local/lib/python3.9/site-packages (from torch>=1.0.0->pytorch-transformers) (4.1.1)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from boto3->pytorch-transformers) (0.5.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from boto3->pytorch-transformers) (1.0.0)\n",
      "Requirement already satisfied: botocore<1.26.0,>=1.25.1 in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from boto3->pytorch-transformers) (1.25.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seclab_taewan/.local/lib/python3.9/site-packages (from requests->pytorch-transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/seclab_taewan/.local/lib/python3.9/site-packages (from requests->pytorch-transformers) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/seclab_taewan/.local/lib/python3.9/site-packages (from requests->pytorch-transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from requests->pytorch-transformers) (2021.10.8)\n",
      "Requirement already satisfied: click in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from sacremoses->pytorch-transformers) (8.1.2)\n",
      "Requirement already satisfied: six in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from sacremoses->pytorch-transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/seclab_taewan/.local/lib/python3.9/site-packages (from sacremoses->pytorch-transformers) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /etc/anaconda3/envs/test/lib/python3.9/site-packages (from botocore<1.26.0,>=1.25.1->boto3->pytorch-transformers) (2.8.2)\n",
      "Installing collected packages: pytorch-transformers\n",
      "Successfully installed pytorch-transformers-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/etc/anaconda3/envs/test/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ! pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b8cb030-0fff-455a-ad73-af159b768a89",
   "metadata": {
    "id": "9b8cb030-0fff-455a-ad73-af159b768a89"
   },
   "source": [
    "The process of doing NER with BERT contains 4 steps:\n",
    "\n",
    "Load data\n",
    "Set data into training embeddings\n",
    "Train model\n",
    "Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2de2d7-f589-4b57-9fcd-77f3b6212e6b",
   "metadata": {
    "executionInfo": {
     "elapsed": 9995,
     "status": "ok",
     "timestamp": 1654607976644,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "9f2de2d7-f589-4b57-9fcd-77f3b6212e6b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm,trange\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "from pytorch_transformers import BertForTokenClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780e92fa-6436-4315-8a37-b05c2d1d5e4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1654607976645,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "780e92fa-6436-4315-8a37-b05c2d1d5e4c",
    "outputId": "3a5fce10-9f28-4039-c885-39db239fb62a"
   },
   "outputs": [],
   "source": [
    "# ! ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61341855-3f59-4622-ad8e-68f99723b852",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 4449,
     "status": "ok",
     "timestamp": 1654607981090,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "61341855-3f59-4622-ad8e-68f99723b852",
    "outputId": "1c2070f3-5376-4e56-928a-51088d6fb0de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>경</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>력</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>증</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>명</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>서</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence # Word Tag\n",
       "0  Sentence: 1    경   O\n",
       "1  Sentence: 1    력   O\n",
       "2  Sentence: 2    증   O\n",
       "3  Sentence: 2    명   O\n",
       "4  Sentence: 2    서   O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(\"./tag_bio_char_.csv\").fillna(method='ffill')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93c4d7f-d375-43fd-964a-096e50647da4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1172,
     "status": "ok",
     "timestamp": 1654607982256,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "d93c4d7f-d375-43fd-964a-096e50647da4",
    "outputId": "5ac3600d-de11-4d6e-987d-3a0d0bfb92da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I-BIR     1732648\n",
       "I-MON     1326159\n",
       "O          965540\n",
       "I-PER      874896\n",
       "B-PER      441439\n",
       "B-BIR      208345\n",
       "B-MON      168237\n",
       "I-ADDR      35585\n",
       "B-ADDR       8759\n",
       "I-POL         240\n",
       "B-POL          70\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.Tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34cdf8e3-58a9-43df-9380-d81cca520c3d",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1654607982256,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "34cdf8e3-58a9-43df-9380-d81cca520c3d"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31628af-87f6-41ca-94f7-c5c262d7eefc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110339,
     "status": "ok",
     "timestamp": 1654608092591,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "f31628af-87f6-41ca-94f7-c5c262d7eefc",
    "outputId": "63b59dfb-4796-4836-90c5-fb9a32eef25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['경', '력']\n"
     ]
    }
   ],
   "source": [
    "getter = SentenceGetter(df_data)\n",
    "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90dc2259-2eb9-47ba-9032-0fd56a201da6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1411,
     "status": "ok",
     "timestamp": 1654608093989,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "90dc2259-2eb9-47ba-9032-0fd56a201da6",
    "outputId": "a0728a0c-0252-47ea-ce4a-67e55bfd5854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['경', '력']\n",
      "['O', 'O']\n"
     ]
    }
   ],
   "source": [
    "#poses = [[s[1] for s in sent] for sent in getter.sentences]\n",
    "labels = [[s[1] for s in sent] for sent in getter.sentences]\n",
    "\n",
    "print (sentences[0])\n",
    "#print (poses[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890fefe6-5868-4f00-ac0c-a909b348c39b",
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1654608093991,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "890fefe6-5868-4f00-ac0c-a909b348c39b"
   },
   "outputs": [],
   "source": [
    "tags_vals = list(set(df_data[\"Tag\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87efb97e-36a0-4096-bf8f-2b278bb5f690",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1654608093993,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "87efb97e-36a0-4096-bf8f-2b278bb5f690",
    "outputId": "5288d876-a20e-4393-ec03-244748ccb916"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-ADDR',\n",
       " 'B-BIR',\n",
       " 'B-MON',\n",
       " 'B-PER',\n",
       " 'B-POL',\n",
       " 'I-ADDR',\n",
       " 'I-BIR',\n",
       " 'I-MON',\n",
       " 'I-PER',\n",
       " 'I-POL',\n",
       " 'O',\n",
       " 'X',\n",
       " '[CLS]',\n",
       " '[SEP]'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add X  label for word piece support\n",
    "# Add [CLS] and [SEP] as BERT need\n",
    "tags_vals.append('X')\n",
    "tags_vals.append('[CLS]')\n",
    "tags_vals.append('[SEP]')\n",
    "tags_vals = set(tags_vals)\n",
    "tags_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "904b63d7-9be6-4377-bd5f-340b165f62ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1654608093993,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "904b63d7-9be6-4377-bd5f-340b165f62ec",
    "outputId": "ce2f075b-ed37-4e24-d3aa-cfc8ad6d283f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\ntag2idx={'B-art': 14,\\n 'B-eve': 16,\\n 'B-geo': 0,\\n 'B-gpe': 13,\\n 'B-nat': 12,\\n 'B-org': 10,\\n 'B-per': 4,\\n 'B-tim': 2,\\n 'I-art': 5,\\n 'I-eve': 7,\\n 'I-geo': 15,\\n 'I-gpe': 8,\\n 'I-nat': 11,\\n 'I-org': 3,\\n 'I-per': 6,\\n 'I-tim': 1,\\n 'X':17,\\n 'O': 9,\\n '[CLS]':18,\\n '[SEP]':19}\\n \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a dict for mapping id to tag name\n",
    "#tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "\n",
    "# Recommend to set it by manual define, good for reusing\n",
    "tag2idx={'B-PER': 1,\n",
    " 'B-ADDR': 3,\n",
    " 'B-BIR': 5,\n",
    " 'B-MON': 7,\n",
    " 'B-POL': 9,\n",
    " 'I-PER': 2,\n",
    " 'I-ADDR': 4,\n",
    " 'I-BIR': 6,\n",
    " 'I-MON': 8,\n",
    " 'I-POL': 10,\n",
    " 'X':11,\n",
    " 'O': 0,\n",
    " '[CLS]':12,\n",
    " '[SEP]':13}\n",
    "'''\n",
    "tag2idx={'B-art': 14,\n",
    " 'B-eve': 16,\n",
    " 'B-geo': 0,\n",
    " 'B-gpe': 13,\n",
    " 'B-nat': 12,\n",
    " 'B-org': 10,\n",
    " 'B-per': 4,\n",
    " 'B-tim': 2,\n",
    " 'I-art': 5,\n",
    " 'I-eve': 7,\n",
    " 'I-geo': 15,\n",
    " 'I-gpe': 8,\n",
    " 'I-nat': 11,\n",
    " 'I-org': 3,\n",
    " 'I-per': 6,\n",
    " 'I-tim': 1,\n",
    " 'X':17,\n",
    " 'O': 9,\n",
    " '[CLS]':18,\n",
    " '[SEP]':19}\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb05ce4-ffc4-45ec-bf02-6c7ff879a60d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1654608107410,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "fdb05ce4-ffc4-45ec-bf02-6c7ff879a60d",
    "outputId": "a8db4650-0b36-4e26-8124-3935180e826b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-ADDR': 3,\n",
       " 'B-BIR': 5,\n",
       " 'B-MON': 7,\n",
       " 'B-PER': 1,\n",
       " 'B-POL': 9,\n",
       " 'I-ADDR': 4,\n",
       " 'I-BIR': 6,\n",
       " 'I-MON': 8,\n",
       " 'I-PER': 2,\n",
       " 'I-POL': 10,\n",
       " 'O': 0,\n",
       " 'X': 11,\n",
       " '[CLS]': 12,\n",
       " '[SEP]': 13}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74d6adc6-7af0-458f-9eb6-f09b8a878b29",
   "metadata": {
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1654608108934,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "74d6adc6-7af0-458f-9eb6-f09b8a878b29"
   },
   "outputs": [],
   "source": [
    "# Mapping index to name\n",
    "tag2name={tag2idx[key] : key for key in tag2idx.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf57dcad-5bff-40df-bb22-5f9a135dec1e",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1654608110037,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "bf57dcad-5bff-40df-bb22-5f9a135dec1e"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "248090e7-f3ba-441a-93f7-a4ea23c0fa3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1654608110989,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "248090e7-f3ba-441a-93f7-a4ea23c0fa3a",
    "outputId": "78dfde21-6532-43dc-a0f7-50119966e577"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 14476339.23B/s]\n"
     ]
    }
   ],
   "source": [
    "# Len of the sentence must be the same as the training model\n",
    "# See model's 'max_position_embeddings' = 512\n",
    "max_len  = 45\n",
    "# load tokenizer, with manual file address or pretrained address\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d022e178-7dbc-422c-b96e-4f9075a55bd0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 405632,
     "status": "ok",
     "timestamp": 1654608517779,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "d022e178-7dbc-422c-b96e-4f9075a55bd0",
    "outputId": "77326940-4754-46a4-9827-36cfa0c804e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0,len:8\n",
      "texts:[CLS] ᄀ ##ᅧ ##ᆼ ᄅ ##ᅧ ##ᆨ [SEP]\n",
      "No.0,len:8\n",
      "lables:[CLS] O X X O X X [SEP]\n",
      "No.1,len:43\n",
      "texts:[CLS] ᄀ ##ᅵ [UNK] ᄒ ##ᅡ ##ᆼ ᄀ ##ᅩ ##ᆼ ᄀ ##ᅩ ##ᆼ ᄒ ##ᅡ ##ᆨ ᄇ ##ᅮ ( ᄋ ##ᅮ ᄌ ##ᅮ ᄒ ##ᅡ ##ᆼ ᄀ ##ᅩ ##ᆼ ᄀ ##ᅩ ##ᆼ ᄒ ##ᅡ ##ᆨ ᄌ ##ᅥ ##ᆫ ᄀ ##ᅩ ##ᆼ ) [SEP]\n",
      "No.1,len:43\n",
      "lables:[CLS] O X O O X X O X X O X X O X X O X O O X O X O X X O X X O X X O X X O X X O X X O [SEP]\n",
      "No.2,len:10\n",
      "texts:[CLS] ᄀ ##ᅪ ##ᆼ ᄉ ##ᅡ ##ᆫ ᄀ ##ᅮ [SEP]\n",
      "No.2,len:10\n",
      "lables:[CLS] B-ADDR X X I-ADDR X X I-ADDR X [SEP]\n",
      "No.3,len:10\n",
      "texts:[CLS] ᄃ ##ᅡ ##ᆯ ᄌ ##ᅥ ##ᆫ ᄅ ##ᅵ [SEP]\n",
      "No.3,len:10\n",
      "lables:[CLS] B-ADDR X X I-ADDR X X I-ADDR X [SEP]\n",
      "No.4,len:12\n",
      "texts:[CLS] 8 0 8 6 1 0 0 0 0 0 [SEP]\n",
      "No.4,len:12\n",
      "lables:[CLS] B-MON I-MON I-MON I-MON I-MON I-MON I-MON I-MON I-MON I-MON [SEP]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = []\n",
    "word_piece_labels = []\n",
    "i_inc = 0\n",
    "for word_list,label in (zip(sentences,labels)):\n",
    "    temp_lable = []\n",
    "    temp_token = []\n",
    "    \n",
    "    # Add [CLS] at the front \n",
    "    temp_lable.append('[CLS]')\n",
    "    temp_token.append('[CLS]')\n",
    "    \n",
    "    for word,lab in zip(word_list,label):\n",
    "        token_list = tokenizer.tokenize(word)\n",
    "        for m,token in enumerate(token_list):\n",
    "            temp_token.append(token)\n",
    "            if m==0:\n",
    "                temp_lable.append(lab)\n",
    "            else:\n",
    "                temp_lable.append('X')  \n",
    "                \n",
    "    # Add [SEP] at the end\n",
    "    temp_lable.append('[SEP]')\n",
    "    temp_token.append('[SEP]')\n",
    "    \n",
    "    tokenized_texts.append(temp_token)\n",
    "    word_piece_labels.append(temp_lable)\n",
    "    \n",
    "    if 5 > i_inc:\n",
    "        print(\"No.%d,len:%d\"%(i_inc,len(temp_token)))\n",
    "        print(\"texts:%s\"%(\" \".join(temp_token)))\n",
    "        print(\"No.%d,len:%d\"%(i_inc,len(temp_lable)))\n",
    "        print(\"lables:%s\"%(\" \".join(temp_lable)))\n",
    "    i_inc +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7559a21-6325-422e-89c6-c180373a21d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12481,
     "status": "ok",
     "timestamp": 1654608530252,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "a7559a21-6325-422e-89c6-c180373a21d7",
    "outputId": "850273c4-284d-4f4d-bcf2-85b6949c6789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  1455 30010 30025  1458 30010 30020   102     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# Make text token into id\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28c54dca-5413-44b2-b4a9-3525032007f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7707,
     "status": "ok",
     "timestamp": 1654608537951,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "28c54dca-5413-44b2-b4a9-3525032007f5",
    "outputId": "0a02d1d5-f0a6-49d9-a9f3-63a71b6d72d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  0 11 11  0 11 11 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# Make label into id, pad with \"O\" meaning others\n",
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels],\n",
    "                     maxlen=max_len, value=tag2idx[\"O\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")\n",
    "print(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46e47647-f5f8-47ba-a6ed-4988976eaac6",
   "metadata": {
    "executionInfo": {
     "elapsed": 30288,
     "status": "ok",
     "timestamp": 1654608568231,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "46e47647-f5f8-47ba-a6ed-4988976eaac6"
   },
   "outputs": [],
   "source": [
    "# For fine tune of predict, with token mask is 1,pad token is 0\n",
    "attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
    "attention_masks[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4430cfe0-33c7-4eda-bd69-0266d07ff8b8",
   "metadata": {
    "executionInfo": {
     "elapsed": 1090,
     "status": "ok",
     "timestamp": 1654608569313,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "4430cfe0-33c7-4eda-bd69-0266d07ff8b8"
   },
   "outputs": [],
   "source": [
    "# Since only one sentence, all the segment set to 0\n",
    "segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
    "segment_ids[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25b06852-0098-4865-9f89-a7819e7046e6",
   "metadata": {
    "executionInfo": {
     "elapsed": 1147,
     "status": "ok",
     "timestamp": 1654608570454,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "25b06852-0098-4865-9f89-a7819e7046e6"
   },
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags,tr_masks, val_masks,tr_segs, val_segs = train_test_split(input_ids, tags,attention_masks,segment_ids, \n",
    "                                                            random_state=4, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7888ad5b-1f61-4297-bf05-09bcb91761c4",
   "metadata": {
    "executionInfo": {
     "elapsed": 8719,
     "status": "ok",
     "timestamp": 1654608579170,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "7888ad5b-1f61-4297-bf05-09bcb91761c4"
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "tr_segs = torch.tensor(tr_segs)\n",
    "val_segs = torch.tensor(val_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76d15dec-0d8f-4a39-8590-aafbf1bc1008",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1654608579171,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "76d15dec-0d8f-4a39-8590-aafbf1bc1008"
   },
   "outputs": [],
   "source": [
    "batch_num = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4c8970b-6957-433b-b18b-3ebc395ac0eb",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1654608579172,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "d4c8970b-6957-433b-b18b-3ebc395ac0eb"
   },
   "outputs": [],
   "source": [
    "# Only set token embedding, attention embedding, no segment embedding\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# Drop last can make batch training better for the last one\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_num,drop_last=True)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "818caa20-9bef-492e-95f9-d7477fb3a001",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13731,
     "status": "ok",
     "timestamp": 1654608592894,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "818caa20-9bef-492e-95f9-d7477fb3a001",
    "outputId": "27211463-cfac-483b-a481-755f6972020b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 433/433 [00:00<00:00, 145733.72B/s]\n",
      "100%|██████████| 440473133/440473133 [00:08<00:00, 50432282.05B/s]\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\",num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2853ae37-75d1-4111-b6dd-82846f2e8d40",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1654608592895,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "2853ae37-75d1-4111-b6dd-82846f2e8d40"
   },
   "outputs": [],
   "source": [
    "model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b30d3d7-b5a2-495f-8e96-a01749078aba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 551,
     "status": "error",
     "timestamp": 1654608593440,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "5b30d3d7-b5a2-495f-8e96-a01749078aba",
    "outputId": "bef12525-84d7-4430-ec14-4037ab9ef8a5"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-cb7b895bb807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12da1f6-00fc-48d5-b049-66c51e2a74e7",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1654608593435,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "a12da1f6-00fc-48d5-b049-66c51e2a74e7"
   },
   "outputs": [],
   "source": [
    "# Add multi GPU support\n",
    "if n_gpu >1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a80e2-df1e-436d-8eb5-f58706d29ce8",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1654608593436,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "941a80e2-df1e-436d-8eb5-f58706d29ce8"
   },
   "outputs": [],
   "source": [
    "# Set epoch and grad max num\n",
    "epochs = 6\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c121f4e-af6c-4584-a941-02589d408af1",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1654608593437,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "6c121f4e-af6c-4584-a941-02589d408af1"
   },
   "outputs": [],
   "source": [
    "# Cacluate train optimiazaion num\n",
    "num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88406709-2a0c-4154-818c-82e7e9906406",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1654608593438,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "88406709-2a0c-4154-818c-82e7e9906406"
   },
   "outputs": [],
   "source": [
    "# True: fine tuning all the layers \n",
    "# False: only fine tuning the classifier layers\n",
    "FULL_FINETUNING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4699a5-0bb6-421a-9ffe-2657747c627d",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1654608593438,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "ac4699a5-0bb6-421a-9ffe-2657747c627d"
   },
   "outputs": [],
   "source": [
    "if FULL_FINETUNING:\n",
    "    # Fine tune model all layer parameters\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    # Only fine tune classifier parameters\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5138c-4a62-4780-9a9f-7a1c7af811ae",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1654608593439,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "37e5138c-4a62-4780-9a9f-7a1c7af811ae"
   },
   "outputs": [],
   "source": [
    "# TRAIN loop\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75da82fb-3035-4ada-b13a-167e6ede376a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "executionInfo": {
     "elapsed": 1126134,
     "status": "error",
     "timestamp": 1654607877034,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "75da82fb-3035-4ada-b13a-167e6ede376a",
    "outputId": "a962e920-3321-416f-92d7-cd6585548302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 739502\n",
      "  Batch size = 32\n",
      "  Num steps = 138660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
      "Epoch:   0%|          | 0/6 [18:45<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-fea835068ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         outputs = model(b_input_ids, token_type_ids=None,\n\u001b[0;32m---> 15\u001b[0;31m         attention_mask=b_input_mask, labels=b_labels)\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_gpu\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, labels, position_ids, head_mask)\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mactive_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 \u001b[0mactive_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactive_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m                 \u001b[0mactive_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactive_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"***** Running training *****\")\n",
    "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
    "print(\"  Batch size = %d\"%(batch_num))\n",
    "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
    "for _ in trange(epochs,desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "        attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss, scores = outputs[:2]\n",
    "        if n_gpu>1:\n",
    "            # When multi gpu, average it\n",
    "            loss = loss.mean()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc4b74-4baa-40e7-b47d-bc9f8d240eed",
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "aborted",
     "timestamp": 1654606060316,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "e3bc4b74-4baa-40e7-b47d-bc9f8d240eed"
   },
   "outputs": [],
   "source": [
    "bert_out_address = 'models/bert_out_model/en09'\n",
    "# Make dir if not exits\n",
    "if not os.path.exists(bert_out_address):\n",
    "        os.makedirs(bert_out_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dec8ff-97e7-422e-b166-d513a6b3e58e",
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "aborted",
     "timestamp": 1654606060319,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "b0dec8ff-97e7-422e-b166-d513a6b3e58e"
   },
   "outputs": [],
   "source": [
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806dfe29-f587-46e2-b238-b912f2deb255",
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "aborted",
     "timestamp": 1654606060321,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "806dfe29-f587-46e2-b238-b912f2deb255"
   },
   "outputs": [],
   "source": [
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(bert_out_address, \"pytorch_model.bin\")\n",
    "output_config_file = os.path.join(bert_out_address, \"config.json\")\n",
    "\n",
    "# Save model into file\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "tokenizer.save_vocabulary(bert_out_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9561a56-4506-4009-ae32-80f437c68f04",
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "aborted",
     "timestamp": 1654606060322,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "b9561a56-4506-4009-ae32-80f437c68f04"
   },
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(bert_out_address,num_labels=len(tag2idx))\n",
    "\n",
    "model.cuda(); # Set model to GPU\n",
    "\n",
    "if n_gpu >1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f834dc0-45a3-4925-9275-f3d9a0b32a41",
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "aborted",
     "timestamp": 1654606060324,
     "user": {
      "displayName": "­진나영",
      "userId": "17533158877537673646"
     },
     "user_tz": -540
    },
    "id": "8f834dc0-45a3-4925-9275-f3d9a0b32a41"
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a1683-ade5-460e-be13-16989db467a9",
   "metadata": {
    "id": "a72a1683-ade5-460e-be13-16989db467a9"
   },
   "outputs": [],
   "source": [
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "print(\"***** Running evaluation *****\")\n",
    "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
    "print(\"  Batch size = {}\".format(batch_num))\n",
    "for step, batch in enumerate(valid_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, input_mask, label_ids = batch\n",
    "    \n",
    "#     if step > 2:\n",
    "#         break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None,\n",
    "        attention_mask=input_mask,)\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0] \n",
    "    \n",
    "    # Get NER predict result\n",
    "    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    # Get NER true result\n",
    "    label_ids = label_ids.to('cpu').numpy()\n",
    "    \n",
    "    \n",
    "    # Only predict the real word, mark=0, will not calculate\n",
    "    input_mask = input_mask.to('cpu').numpy()\n",
    "    \n",
    "    # Compare the valuable predict result\n",
    "    for i,mask in enumerate(input_mask):\n",
    "        # Real one\n",
    "        temp_1 = []\n",
    "        # Predict one\n",
    "        temp_2 = []\n",
    "        \n",
    "        for j, m in enumerate(mask):\n",
    "            # Mark=0, meaning its a pad word, dont compare\n",
    "            if m:\n",
    "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
    "                    temp_1.append(tag2name[label_ids[i][j]])\n",
    "                    temp_2.append(tag2name[logits[i][j]])\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "            \n",
    "        y_true.append(temp_1)\n",
    "        y_pred.append(temp_2)\n",
    "\n",
    "        \n",
    "\n",
    "print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
    "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "# Get acc , recall, F1 result report\n",
    "report = classification_report(y_true, y_pred,digits=4)\n",
    "\n",
    "# Save the report into file\n",
    "output_eval_file = os.path.join(bert_out_address, \"eval_results.txt\")\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    print(\"***** Eval results *****\")\n",
    "    print(\"\\n%s\"%(report))\n",
    "    print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
    "    print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "    \n",
    "    writer.write(\"f1 socre:\\n\")\n",
    "    writer.write(str(f1_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\nAccuracy score:\\n\")\n",
    "    writer.write(str(accuracy_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\n\")  \n",
    "    writer.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3d587-8487-4d07-8c95-bcc03b64316c",
   "metadata": {
    "id": "bcc3d587-8487-4d07-8c95-bcc03b64316c"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentences = \"I bought a new iphone and its Iphone X from Apple\"\n",
    "word_tokens = nltk.word_tokenize(sentences)\n",
    "pos_tags = nltk.pos_tag(word_tokens)\n",
    "tokenized_texts = []\n",
    "word_piece_labels = []\n",
    "i_inc = 0\n",
    "temp_token = []\n",
    "# Add [CLS] at the front \n",
    "temp_token.append('[CLS]')\n",
    "for word,lab in pos_tags:\n",
    "    token_list = tokenizer.tokenize(word)\n",
    "    for m,token in enumerate(token_list):\n",
    "        temp_token.append(token)\n",
    "# Add [SEP] at the end\n",
    "temp_token.append('[SEP]')\n",
    "tokenized_texts.append(temp_token)\n",
    "print(\"texts:%s\"%(\" \".join(temp_token)))\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(input_ids[0])\n",
    "b_input_mask = \"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
